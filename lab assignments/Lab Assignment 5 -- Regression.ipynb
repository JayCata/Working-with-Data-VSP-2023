{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56fb16cb",
   "metadata": {},
   "source": [
    "## Lab Assignment 5 -- Regression\n",
    "In this lab, you will complete an exercises related to the lecture material on regression. Then, you will compete with your fellow classmates to see who can best predict housing prices. \n",
    "\n",
    "**IMPORTANT:** Before submitting, make sure you restart the kernel and run all cells sequentially. After all cells have executed, then save the file for submission.  This is very important for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa22484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this line\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "np.random.seed(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8137271",
   "metadata": {},
   "source": [
    "## Exercise 1 -- Generating & Analyzing Fake Data\n",
    "In this exercise, we will generate some fake data as we did in the lecture on regression trees. Then, we will use it on a series of regression problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509af2e9",
   "metadata": {},
   "source": [
    "## Exercise 1a -- Generating the Data\n",
    "Complete the following steps:\n",
    "1. Define a function called `generate_data` that takes two arguments, an integer `n` and a boolean `square`. `square` should have a default argument of `False`.\n",
    "2. Generate an array called `X` and set it equal to `np.random.randn((n,1))`. This creates an $n$-vector of [**standard normal random variables**](https://en.wikipedia.org/wiki/Normal_distribution).\n",
    "3. Turn `X` into an $nx2$ array by concatenating it with an $n$-vector of ones (**Hint**: use `np.ones((n,1))` and `np.concatenate()`). Make sure that the array of ones serves as the first column. \n",
    "3. Define an array called `beta` and set it equal to the array [1, 3.14]\n",
    "4. Define a variable called `epsilon` and set it equal to `np.random.randn(n)*0.3` \n",
    "5. Then, using `X`, `beta`, and `epsilon`, create a variable named `y` which is equal to \n",
    "    - `np.matmul(X, beta) + epsilon` if square is `False`\n",
    "    - `np.matmul(X ** 2, beta) + epsilon` if `square` is `True`.\n",
    "    \n",
    "6. Your output should return `X`and `y`\n",
    "7. Test your function in the cell below with `n=100` and no argument for `square`. Save the output to `X100` and `y100` respectively. Afterwards, print `y100[50]`.\n",
    "\n",
    "Answer the following questions in the Markdown cell below:\n",
    "1. Is this a bivariate or multivariate linear regression model? Why?\n",
    "2. What is the purpose of  including this `epsilon`? What aspect of real data are we trying to mimic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca021c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1a -- Test function and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d47ea4",
   "metadata": {},
   "source": [
    "### Reponse to Exercise 1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ee923",
   "metadata": {},
   "source": [
    "## Exercise 1b -- Standard Linear Regression\n",
    "Using `sklearn`, fit a linear regression model on `y100` and `X100`. When intializing your model, set `fit_intercept` equal to `False` and call your linear model `lr_model_1`. Then, print the estimated coefficients and answer the following question in the Markdown cell below.\n",
    "- What are the coefficient estimates? What values are they close to? Why does this make sense?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9955e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1b -- fit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5d044",
   "metadata": {},
   "source": [
    "### Response to Exercise 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c9960",
   "metadata": {},
   "source": [
    "## Exercise 1c -- Linear Regression with Quadratic Terms\n",
    "Using `generate_data(100, True)`, create two variables `y100_2` and `X100_2`. Then, repeat the steps from **Exercise 1b** above using `X100_2` and `y100_2` instead of `X_100` and `y_100`.  Call your new model `linear_model_2`.\n",
    "\n",
    "Answer the following questions in the Markdown cell below:\n",
    "\n",
    "1. What are the coefficient estimates? Are they similar to the coefficients from **Exercise 1b**? Why or why not?\n",
    "\n",
    "If your estimates were not similar, create a variable `X100_2_sq` in the third cell below that can be used instead of `X100_2` so that your estimates are similar again. Repeat the same process again but call your `lr_model_3`. Print your new estimated coefficients.\n",
    "\n",
    "In the markdown cell below, answer the following question:\n",
    "\n",
    "2. How did you modify `X100_2` to attain similar coefficients? Why did this work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be504991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1c -- generate variables and repeat regression fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064117e4",
   "metadata": {},
   "source": [
    "### Response to Exercise 1c -- Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1c -- modify X100_2 and run new regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67e55d",
   "metadata": {},
   "source": [
    "### Response to Exercise 1c -- Quesiton 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebaa1d3",
   "metadata": {},
   "source": [
    "### Exercise 1d -- Unnecessary Quadratic Terms\n",
    "Now we are going to see what happens when we estimate a model that only has linear terms using both linear and quadratic terms. Complete the following steps:\n",
    "1. Create an $nx3$ array called `X100_ext` by concatenating `X100` with a column that is equal to the square of elements in the second column. Make sure this new column is the third column. Note that `np.concatenate` requires that both arrays are of the same dimension. You may have to use the method [`.reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
    "2. Now repeat the steps of **Exercise 1b** with `X100_ext`. Make sure you print the estimated coefficients.\n",
    "\n",
    "Answer the following questions in the Markdown cell below:\n",
    "1. Are the first two coefficients different from their respective counterparts in part **Exercise 1b**? Why do you think this is?\n",
    "2.  Is the third coeffcient close to 0 or large? Why do you think this is?\n",
    "3. Do you think these estimates are accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba894f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1d -- Create X100_ext here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50115717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1d -- Repeat exercise 1b here\n",
    "lr_model_4 = linear_model.LinearRegression(fit_intercept = False)\n",
    "lr_model_4.fit(X100_ext, y100)\n",
    "lr_model_4.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18eab25",
   "metadata": {},
   "source": [
    "### Response to Exercise 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fd11d",
   "metadata": {},
   "source": [
    "## Exercise 1e -- Regression Plots\n",
    "Following the notes in the plotting lectures complete the following steps:\n",
    "1. Using `subplots()` initialize a figure with 4 figures in a $2x2$ grid\n",
    "2. Plot the following in the indicated location. \n",
    "    - **Top-left**  -- a line plot of `lr_model_1` and a scatter plot of the data used to generate `lr_model_1`.\n",
    "    - **Bottom-left**  -- a line plot of `lr_model_2` and a scatter plot of the data used to generate `lr_model_2`\n",
    "    - **Bottom-right** -- a line plot of `lr_model_3` and a scatter plot of the data used to generate `lr_model_3`\n",
    "    - **Top-right** -- a line plot of `lr_model_4` and a scatter plot of the data used to generate `lr_model_4`\n",
    "    \n",
    "For the plots above, \n",
    "- make your lines red, \n",
    "- title your plots (e.g. \"Linear Model 1\"),\n",
    "- use `np.linspace(-4,4,200)` as your domain when plotting the lines,\n",
    "- call `fig.tight_layout()` so your plot is not cluttered\n",
    "\n",
    "3. Using the `metrics` submodule of `sklearn`, print the `in-sample` mean squared errors of each model using f strings. Your stings should looke like this: \"MSE of Linear Model 1 is .3\"  \n",
    "**Hints:** . \n",
    "- To plot on the top left axis, you will need to work with `axes.flat[0]` . The remaining axes are indexed by 1, 2, and 3.\n",
    "- If you choose to used the `.predict()` to plot your lines, keep in mind you need to provide it with the correctly shaped input. \n",
    "- When calculating the means within a loop, it may hep to create a list that contains the four linear models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb2cad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1e -- plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de691e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1e -- mean squared errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81baa272",
   "metadata": {},
   "source": [
    "### Exercise 1f -- Functional Misspecification\n",
    "**Functional Misspecification** is used to describe the situation where the functional form of the regression model we are estimating is not the same as the functional form of the true data generating process. Answer the following question in the markdown cell below:\n",
    "- Which of the four linear models do you think are well-specified? Which ones are not? Is including extra terms problematic when it comes to being well-specified. What about excluding the terms found in the true data generating process?\n",
    "- How does misspecification manifest itself in the plots? How about in the mean squared errors? \n",
    "- After doing this exercise, do you think it is important to investigate the relationship between variables before determining your regression specification? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d3f378",
   "metadata": {},
   "source": [
    "### Response to Exercise 1f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7d5c8",
   "metadata": {},
   "source": [
    "### Exercise 1g -- Lasso\n",
    "Finally, we will run lasso on our fake data. Complete the following steps:\n",
    "1. Generate `X1000` and `y1000` using `generate_data(1000)`\n",
    "2. Create an `1000x3` array called `X1000_ext` which is created in a anaglous fashion to `X100_ext`. \n",
    "3. Follow the lecture notes to create a standardized version of `X1000_ext` called `X1000_ext_scl`. You will need to import the `preprocessing` submodule of sklearn.\n",
    "4. Check to make sure your means and variances. You should see that everything looks good except for our intercept has a variance of $0$. You actually do not want to standardize an intercept but we still need it! Replace the first column of  `X1000_ext_scl` with a fresh column of ones using `np.ones(1000)`.\n",
    "5. Create a dataframe version of `X1000_ext_scl` called `X_lasso_df` and rename the columns to \"intercept\", \"x\", and \"x_sq\" respectively.Then call `X_lasso_df` at the bottom of the cell.\n",
    "6. Copy and paste the Lasso path code from the lecture notes into the second cell below. Adapt it so it works for `X_lasso_df` and `y1000`.\n",
    "\n",
    "\n",
    "In the Markdown cell below, answer the following questions:\n",
    "1. Characterize `X_sq`'s lasso path. Why was this behavior predictable?    Reference linear model 4 or the true DGP in your answer.\n",
    "2. Without checking, do you think a low or high value for alpha would be chosen by cross validation? To help you answer this question, think about what the true coefficients are and whether or not higher alphas bring the lasso coefficients closer to their true counterparts or farther away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250202b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1g -- Steps 1-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfec5de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1g -- Step 5 copy code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
